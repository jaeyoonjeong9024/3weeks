import pandas as pd
from sklearn.model_selection import train_test_split

# 1. Scikit-Learn 라이브러리에서 필요한 도구들 불러오기
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier      # KNN 모델 추가
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix

# ---------------------------------
# 2. 데이터 준비 및 전처리
# ---------------------------------

# Colab에 업로드된 weather.csv 파일을 불러옵니다.
df = pd.read_csv("/content/drive/MyDrive/weather.csv")

# 'Location' 컬럼만 제거
df = df.drop(columns=['Location'])

# 'Date' 컬럼을 날짜 타입으로 변환 후 년, 월, 일로 분리
df['Date'] = pd.to_datetime(df['Date'])
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df = df.drop(columns=['Date']) # 기존 Date 컬럼은 제거

# 결측치(NaN) 채우기
# - 숫자형 데이터는 평균값으로 채움
for col in df.select_dtypes(include='number').columns:
    df[col] = df[col].fillna(df[col].mean())
# - 문자형(범주형) 데이터는 가장 많이 등장하는 값(최빈값)으로 채움
for col in df.select_dtypes(include='object').columns:
    df[col] = df[col].fillna(df[col].mode()[0])

# 문자형 데이터를 숫자로 변환 (Label Encoding)
categorical_columns = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']
for col in categorical_columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# ---------------------------------
# 3. 데이터 분리 및 스케일링
# ---------------------------------

# 입력(X)과 정답(y) 데이터 분리
X = df.drop(columns=['RainTomorrow'])
y = df['RainTomorrow']

# 입력(X) 데이터의 스케일을 표준화합니다. (KNN과 Logistic Regression 성능 향상에 도움)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ---------------------------------
# 4. 훈련 및 테스트 데이터 분리
# ---------------------------------

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,         # 스케일링된 X와 숫자로 바뀐 y
    test_size=0.2,       # 테스트 데이터 비율 20%
    stratify=y,          # 원본 데이터의 비 유무 비율을 유지하며 분리
    random_state=42      # 재현성을 위한 시드 고정
)

# ---------------------------------
# 5. 모델 학습 및 평가
# ---------------------------------

# 비교할 모델들을 딕셔너리 형태로 준비
models = {
    'KNN': KNeighborsClassifier(n_neighbors=5), # KNN 모델 추가 (k=5)
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000)
}

# 반복문을 통해 각 모델을 학습하고 평가 결과를 출력
for name, model in models.items():
    # 모델 학습
    model.fit(X_train, y_train)
    
    # 예측
    y_pred = model.predict(X_test)
    
    # 평가
    accuracy = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    
    # 결과 출력
    print(f"\n===== {name} 모델 평가 결과 =====")
    print(f"정확도 (Accuracy): {accuracy:.4f}")
    print("혼동 행렬 (Confusion Matrix):")
    print(cm)
