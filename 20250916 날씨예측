import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# -----------------------------
# 1) 데이터 준비
# -----------------------------
# Colab에 업로드된 weather.csv 파일을 불러옵니다.
df = pd.read_csv("/content/drive/MyDrive/weather.csv")
print(f"원본 데이터 크기: {df.shape}")

# -----------------------------
# 2) 결측치 확인 및 제거
# -----------------------------
print("\n=== 결측치 확인 ===")
print("결측치 개수:")
print(df.isnull().sum())

# 결측치가 있는 행을 모두 제거
df = df.dropna()

print(f"\n결측치 제거 후 데이터 크기: {df.shape}")
print("결측치 제거 후 확인:")
print(df.isnull().sum())

# -----------------------------
# 3) 불필요한 컬럼 제거 및 날짜 처리
# -----------------------------
print("\n=== 컬럼 확인 ===")
print("전체 컬럼명:", df.columns.tolist())

# 'Location' 컬럼 제거 (있는 경우에만)
if 'Location' in df.columns:
    df = df.drop(columns=['Location'])

# 'Date' 컬럼을 날짜 타입으로 변환 후 년, 월, 일로 분리
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])
    df['Year'] = df['Date'].dt.year
    df['Month'] = df['Date'].dt.month
    df['Day'] = df['Date'].dt.day
    df = df.drop(columns=['Date'])  # 기존 Date 컬럼은 제거

print("처리 후 컬럼명:", df.columns.tolist())

# -----------------------------
# 4) 모든 레이블을 숫자로 변형 (Label Encoding)
# -----------------------------
print("\n=== Label Encoding 수행 ===")
label_encoders = {}

# 문자형 컬럼들을 찾아서 숫자로 변환
for column in df.columns:
    if df[column].dtype == 'object':
        print(f"인코딩 중: {column}")
        label_encoders[column] = LabelEncoder()
        df[column] = label_encoders[column].fit_transform(df[column])

print("Label Encoding 완료")

# -----------------------------
# 5) 입력과 출력 분리
# -----------------------------
print("\n=== 입력(X)과 출력(y) 분리 ===")
X = df.drop(columns=['RainTomorrow'])
y = df['RainTomorrow']

print(f"X shape: {X.shape}")
print(f"y shape: {y.shape}")

# -----------------------------
# 6) 훈련과 테스트 데이터 분리
# -----------------------------
print("\n=== 훈련/테스트 데이터 분리 ===")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print(f"훈련 데이터 크기: X_train {X_train.shape}, y_train {y_train.shape}")
print(f"테스트 데이터 크기: X_test {X_test.shape}, y_test {y_test.shape}")

# -----------------------------
# 7) 모델 구성
# -----------------------------
print("\n=== 모델 구성 ===")
knn = KNeighborsClassifier(n_neighbors=5)
dt = DecisionTreeClassifier(random_state=42)
rf = RandomForestClassifier(n_estimators=200, random_state=42)
lr = LogisticRegression(max_iter=500)

# -----------------------------
# 8) 모델 학습
# -----------------------------
print("\n=== 모델 학습 ===")
knn.fit(X_train, y_train)
dt.fit(X_train, y_train)
rf.fit(X_train, y_train)
lr.fit(X_train, y_train)
print("모든 모델 학습 완료!")

# -----------------------------
# 9) 예측결과 생성
# -----------------------------
print("\n=== 예측 수행 ===")
knn_y_pred = knn.predict(X_test)
dt_y_pred = dt.predict(X_test)
rf_y_pred = rf.predict(X_test)
lr_y_pred = lr.predict(X_test)

# -----------------------------
# 10) 예측결과와 정답을 비교한 정확도 평가
# -----------------------------
print("\n=== 모델 성능 평가 ===")

knn_acc = accuracy_score(y_test, knn_y_pred)
dt_acc = accuracy_score(y_test, dt_y_pred)
rf_acc = accuracy_score(y_test, rf_y_pred)
lr_acc = accuracy_score(y_test, lr_y_pred)

print("=== KNN Test Accuracy ===")
print(f"KNN : {knn_acc:.4f}")
print("혼동 행렬 (Confusion Matrix):")
print(confusion_matrix(y_test, knn_y_pred))

print("\n=== DT Test Accuracy ===")
print(f"Decision Tree : {dt_acc:.4f}")
print("혼동 행렬 (Confusion Matrix):")
print(confusion_matrix(y_test, dt_y_pred))

print("\n=== RF Test Accuracy ===")
print(f"Random Forest : {rf_acc:.4f}")
print("혼동 행렬 (Confusion Matrix):")
print(confusion_matrix(y_test, rf_y_pred))

print("\n=== LR Test Accuracy ===")
print(f"Logistic Reg. : {lr_acc:.4f}")
print("혼동 행렬 (Confusion Matrix):")
print(confusion_matrix(y_test, lr_y_pred))
